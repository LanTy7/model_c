{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM 二分类模型 - 批量预测\n",
    "\n",
    "加载训练好的模型，对FASTA文件进行批量ARG预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ================== 路径配置（请修改）==================\n",
    "MODEL_PATH = \"/home/mayue/model_c/binary/model_train/well-trained/bilstm_20260206_1422.pth\"  # 训练保存的模型\n",
    "\n",
    "# 二选一：\n",
    "# 1) INPUT_PATH：只测试单个 .faa/.fasta 文件（推荐用于先跑通流程）\n",
    "# 2) INPUT_DIR：批量测试目录下所有 .faa/.fasta 文件\n",
    "INPUT_PATH = \"/home/mayue/bilstm/data/predict_sequence/prodigal_result_remove/CRR029083_bin.1_remove.faa\"  # 例如：/path/to/xxx.faa\n",
    "# INPUT_DIR = \"./binary_test_out\"   # 例如：/path/to/faa_dir\n",
    "\n",
    "OUTPUT_DIR = \"./results\"  # 输出目录\n",
    "THRESHOLD = 0.5  # 预测阈值\n",
    "\n",
    "# 输出控制：\n",
    "SAVE_PRED_FASTA = True   # 是否输出预测为 ARG 的 FASTA（供多分类使用）\n",
    "SAVE_SCORES_CSV = True   # 是否输出全量序列的预测分数 CSV（用于真实性能评估）\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型与数据处理定义\n",
    "\n",
    "**注意**: 这里的定义必须与训练代码完全一致！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 氨基酸编码字典（必须与训练一致）\n",
    "AMINO_ACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "AA_DICT = {aa: i + 1 for i, aa in enumerate(AMINO_ACIDS)}\n",
    "AA_DICT.update({'X': 21, 'PAD': 0})\n",
    "\n",
    "def seq_to_indices(sequence, max_length):\n",
    "    \"\"\"将氨基酸序列转换为索引数组\"\"\"\n",
    "    indices = [AA_DICT.get(aa, 21) for aa in sequence]\n",
    "    indices = indices[:max_length]\n",
    "    if len(indices) < max_length:\n",
    "        indices += [0] * (max_length - len(indices))\n",
    "    return np.array(indices, dtype=np.int64)\n",
    "\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    \"\"\"BiLSTM + Global Pooling 二分类模型（必须与训练一致）\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            config['vocab_size'], \n",
    "            config['embedding_dim'], \n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config['embedding_dim'],\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=config['dropout'] if config['num_layers'] > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config['hidden_size'] * 4, config['hidden_size']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(config['hidden_size'], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        output, _ = self.lstm(emb)\n",
    "        max_pool, _ = torch.max(output, dim=1)\n",
    "        avg_pool = torch.mean(output, dim=1)\n",
    "        features = torch.cat([max_pool, avg_pool], dim=1)\n",
    "        return self.classifier(self.dropout(features))\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    \"\"\"推理用数据集（返回索引 + 元信息，便于输出全量 CSV）\"\"\"\n",
    "    def __init__(self, fasta_file, max_length):\n",
    "        self.records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        seq_str = str(record.seq).upper()\n",
    "        x = torch.from_numpy(seq_to_indices(seq_str, self.max_length))\n",
    "        return x, record.id, len(seq_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 加载模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/mayue/model_c/binary/model_train/well-trained/bilstm_20260206_1422.pth\n",
      "Model config: {'vocab_size': 22, 'embedding_dim': 48, 'hidden_size': 48, 'num_layers': 1, 'dropout': 0.5, 'max_length': 1000}\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 加载模型（自动读取保存的配置）\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "config = checkpoint['config']\n",
    "print(f\"Model config: {config}\")\n",
    "\n",
    "model = BiLSTMModel(config).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 批量预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files to process\n",
      "\n",
      "Done! Total predicted ARG sequences written: 334\n"
     ]
    }
   ],
   "source": [
    "# 容错：如果未运行“路径配置”cell，给关键变量设置默认值，避免 NameError\n",
    "INPUT_PATH = globals().get('INPUT_PATH', '')\n",
    "INPUT_DIR = globals().get('INPUT_DIR', '')\n",
    "OUTPUT_DIR = globals().get('OUTPUT_DIR', './predicted_results')\n",
    "THRESHOLD = globals().get('THRESHOLD', 0.5)\n",
    "SAVE_PRED_FASTA = globals().get('SAVE_PRED_FASTA', True)\n",
    "SAVE_SCORES_CSV = globals().get('SAVE_SCORES_CSV', True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def predict_file(model, input_path, config, threshold, output_dir, save_pred_fasta=True, save_scores_csv=True):\n",
    "    \"\"\"对单个FASTA/FAA文件进行预测，并按需输出：预测阳性 FASTA + 全量分数 CSV\"\"\"\n",
    "    dataset = InferenceDataset(input_path, config['max_length'])\n",
    "    if len(dataset) == 0:\n",
    "        return 0\n",
    "    \n",
    "    filename = os.path.basename(input_path)\n",
    "    pred_fasta_path = os.path.join(output_dir, f\"{filename}_pred.fasta\")\n",
    "    scores_csv_path = os.path.join(output_dir, f\"{filename}_scores.csv\")\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "    arg_records = []\n",
    "    rows = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_i, batch in enumerate(loader):\n",
    "            inputs, ids, lens = batch\n",
    "            inputs = inputs.to(device)\n",
    "            logits = model(inputs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "            \n",
    "            for i, prob in enumerate(probs):\n",
    "                global_idx = batch_i * loader.batch_size + i\n",
    "                record = dataset.records[global_idx]\n",
    "                pred = 1 if prob > threshold else 0\n",
    "                rows.append({\n",
    "                    'FileName': filename,\n",
    "                    'SequenceID': record.id,\n",
    "                    'SeqLen': int(lens[i]),\n",
    "                    'ARG_Prob': float(prob),\n",
    "                    'ARG_Pred': int(pred),\n",
    "                    'Threshold': float(threshold),\n",
    "                })\n",
    "                if pred == 1 and save_pred_fasta:\n",
    "                    record.description += f\" [ARG_prob={prob:.3f}]\"\n",
    "                    arg_records.append(record)\n",
    "    \n",
    "    if save_pred_fasta and arg_records:\n",
    "        SeqIO.write(arg_records, pred_fasta_path, \"fasta\")\n",
    "    \n",
    "    if save_scores_csv:\n",
    "        with open(scores_csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()) if rows else [\n",
    "                'FileName','SequenceID','SeqLen','ARG_Prob','ARG_Pred','Threshold'\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            for r in rows:\n",
    "                writer.writerow(r)\n",
    "    \n",
    "    return len(arg_records)\n",
    "\n",
    "\n",
    "# 获取待处理文件（优先 INPUT_PATH）\n",
    "if INPUT_PATH:\n",
    "    all_files = [INPUT_PATH]\n",
    "else:\n",
    "    if not INPUT_DIR:\n",
    "        raise ValueError('请设置 INPUT_PATH（单文件）或 INPUT_DIR（目录）')\n",
    "    all_files = glob.glob(os.path.join(INPUT_DIR, \"*.faa\")) + glob.glob(os.path.join(INPUT_DIR, \"*.fasta\"))\n",
    "\n",
    "print(f\"Found {len(all_files)} files to process\")\n",
    "\n",
    "# 批量处理\n",
    "total_args = 0\n",
    "for i, input_path in enumerate(all_files):\n",
    "    n_args = predict_file(model, input_path, config, THRESHOLD, OUTPUT_DIR, SAVE_PRED_FASTA, SAVE_SCORES_CSV)\n",
    "    total_args += n_args\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Progress: {i+1}/{len(all_files)}\")\n",
    "\n",
    "print(f\"\\nDone! Total predicted ARG sequences written: {total_args}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gene_pred)",
   "language": "python",
   "name": "gene_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
