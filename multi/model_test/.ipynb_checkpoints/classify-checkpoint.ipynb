{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM 多分类模型 - 批量预测\n",
    "\n",
    "加载训练好的模型，对ARG序列进行类别分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ================== 路径配置（请修改）==================\n",
    "MODEL_PATH = \"/home/mayue/model_c/multi/model_train/well-trained/bilstm_multi_20260205_1516.pth\"  # 训练保存的模型\n",
    "INPUT_DIR = \"/home/mayue/data/results_prescreen50\"                      # 二分类预测出的ARG文件夹\n",
    "OUTPUT_CSV = \"/home/mayue/data/results/classification_results.csv\"                # 输出结果\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型与数据处理定义\n",
    "\n",
    "**注意**: 这里的定义必须与训练代码完全一致！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 氨基酸编码字典（必须与训练一致）\n",
    "AMINO_ACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "AA_DICT = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "AA_DICT.update({\n",
    "    'B': [AA_DICT['D'], AA_DICT['N']],\n",
    "    'Z': [AA_DICT['E'], AA_DICT['Q']],\n",
    "    'J': [AA_DICT['I'], AA_DICT['L']],\n",
    "    'X': 'ANY',\n",
    "    'PAD': 20\n",
    "})\n",
    "\n",
    "def one_hot_encode(sequence, max_length):\n",
    "    \"\"\"将氨基酸序列转换为one-hot编码\"\"\"\n",
    "    encoding = np.zeros((max_length, 21), dtype=np.float32)\n",
    "    for i in range(min(len(sequence), max_length)):\n",
    "        aa = sequence[i]\n",
    "        if aa in AA_DICT:\n",
    "            idx = AA_DICT[aa]\n",
    "            if isinstance(idx, list):\n",
    "                for j in idx:\n",
    "                    encoding[i, j] = 0.5\n",
    "            elif idx == 'ANY':\n",
    "                encoding[i, :20] = 0.05\n",
    "            else:\n",
    "                encoding[i, idx] = 1.0\n",
    "        else:\n",
    "            encoding[i, :20] = 0.05\n",
    "    if len(sequence) < max_length:\n",
    "        encoding[len(sequence):, 20] = 1.0\n",
    "    return encoding\n",
    "\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    \"\"\"BiLSTM + Global Pooling 多分类模型（必须与训练一致）\"\"\"\n",
    "    \n",
    "    def __init__(self, config, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config['embedding_size'],\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=config['dropout'] if config['num_layers'] > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config['hidden_size'] * 4, config['hidden_size']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(config['hidden_size'], num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)  # (batch, seq_len, hidden*2)\n",
    "        \n",
    "        # Masked Global Pooling（必须与训练一致，避免 PAD 污染 max/mean pooling）\n",
    "        pad_flag = x[:, :, 20]  # one-hot 的 PAD 通道\n",
    "        valid_mask = pad_flag < 0.5\n",
    "        mask = valid_mask.unsqueeze(-1)\n",
    "        \n",
    "        output_masked = output.masked_fill(~mask, -1e9)\n",
    "        max_pool, _ = torch.max(output_masked, dim=1)\n",
    "        \n",
    "        mask_f = mask.float()\n",
    "        sum_pool = (output * mask_f).sum(dim=1)\n",
    "        denom = mask_f.sum(dim=1).clamp(min=1.0)\n",
    "        avg_pool = sum_pool / denom\n",
    "        \n",
    "        features = torch.cat([max_pool, avg_pool], dim=1)\n",
    "        return self.classifier(self.dropout(features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 加载模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/mayue/model_c/multi/model_train/well-trained/bilstm_multi_20260205_1516.pth\n",
      "Model config: {'embedding_size': 21, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4}\n",
      "Classes: ['MLS', 'aminocoumarin', 'aminoglycoside', 'beta-lactam', 'diaminopyrimidine', 'efflux', 'glycopeptide', 'macrolide', 'multidrug', 'peptide', 'phenicol', 'phosphonic', 'quinolone', 'rifamycin', 'sulfonamide', 'tetracycline', 'Others']\n",
      "Max length: 657\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 加载模型（自动读取保存的配置）\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "\n",
    "# 从checkpoint中读取配置\n",
    "config = checkpoint['model_config']\n",
    "class_names = checkpoint['class_names']\n",
    "max_length = checkpoint['max_length']\n",
    "\n",
    "print(f\"Model config: {config}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Max length: {max_length}\")\n",
    "\n",
    "# 初始化并加载模型\n",
    "model = BiLSTMClassifier(config, len(class_names)).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 批量预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(model, sequences, metadata, class_names, max_length):\n",
    "    \"\"\"处理一个Batch并返回结果\"\"\"\n",
    "    # 编码\n",
    "    encoded = np.array([one_hot_encode(seq, max_length) for seq in sequences])\n",
    "    inputs = torch.tensor(encoded, dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        max_probs, preds = torch.max(probs, dim=1)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(preds)):\n",
    "        file_name, seq_id, seq_str = metadata[i]\n",
    "        pred_class = class_names[preds[i].item()]\n",
    "        prob = max_probs[i].item()\n",
    "        results.append({\n",
    "            'FileName': file_name,\n",
    "            'SequenceID': seq_id,\n",
    "            'PredictedClass': pred_class,\n",
    "            'Probability': prob,\n",
    "            'Sequence': seq_str\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_classification():\n",
    "    \"\"\"批量分类\"\"\"\n",
    "    # 获取所有输入文件\n",
    "    files = glob.glob(os.path.join(INPUT_DIR, \"*.fasta\")) + \\\n",
    "            glob.glob(os.path.join(INPUT_DIR, \"*.faa\"))\n",
    "    print(f\"Found {len(files)} files to process\")\n",
    "    \n",
    "    all_results = []\n",
    "    batch_size = 256\n",
    "    batch_seqs = []\n",
    "    batch_meta = []\n",
    "    \n",
    "    for file_path in tqdm(files, desc=\"Processing\"):\n",
    "        try:\n",
    "            records = list(SeqIO.parse(file_path, \"fasta\"))\n",
    "            if not records:\n",
    "                continue\n",
    "            \n",
    "            file_name = os.path.basename(file_path)\n",
    "            \n",
    "            for record in records:\n",
    "                seq_str = str(record.seq).upper()\n",
    "                batch_seqs.append(seq_str)\n",
    "                batch_meta.append((file_name, record.id, seq_str))\n",
    "                \n",
    "                if len(batch_seqs) >= batch_size:\n",
    "                    results = process_batch(model, batch_seqs, batch_meta, class_names, max_length)\n",
    "                    all_results.extend(results)\n",
    "                    batch_seqs = []\n",
    "                    batch_meta = []\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 处理剩余数据\n",
    "    if batch_seqs:\n",
    "        results = process_batch(model, batch_seqs, batch_meta, class_names, max_length)\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    # 保存结果\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"\\nDone! Results saved to: {OUTPUT_CSV}\")\n",
    "    print(f\"Total sequences classified: {len(df)}\")\n",
    "    \n",
    "    # 打印统计\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['PredictedClass'].value_counts())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 运行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 50/50 [00:08<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Results saved to: /home/mayue/data/results/classification_results.csv\n",
      "Total sequences classified: 28057\n",
      "\n",
      "Class distribution:\n",
      "PredictedClass\n",
      "beta-lactam          7810\n",
      "aminoglycoside       7420\n",
      "multidrug            3755\n",
      "glycopeptide         2187\n",
      "MLS                  2101\n",
      "peptide              1020\n",
      "tetracycline         1005\n",
      "phosphonic            929\n",
      "Others                373\n",
      "phenicol              354\n",
      "sulfonamide           313\n",
      "efflux                202\n",
      "rifamycin             200\n",
      "macrolide             174\n",
      "diaminopyrimidine     123\n",
      "quinolone              79\n",
      "aminocoumarin          12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 运行分类\n",
    "results_df = run_classification()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gene_pred)",
   "language": "python",
   "name": "gene_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
